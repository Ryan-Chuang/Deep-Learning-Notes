# 应用机器学习的建议
## 决定下一步做什么
 + 调试学习算法（debugging a learning algorithm）
  + 获取更多的训练集
  + 尝试少一些特征量（features）
  + 获取更多的特征量
  + 尝试多项式特征量（如x1^2, x1 * x2等）
  + 尝试减小lambda或增大lambda（正则化参数）
 + 机器学习诊断法（ML diagnostic）
  + 通过一项测试来了解算法哪里出了问题，或者哪里是OK的，并且能够知道如何改进算法性能。
## 评估假设  
 + 将数据集分成训练集和测试集（7：3）；
  + 通过训练集来学习参数θ；
  + 计算测试集的误差J(θ)_test；
   + 线性回归的误差计算：
     + J(θ)_test = 1/2m_test * sum(h(x)_test - y_test)
   + 逻辑回归的误差计算(有两种计算方法)：
     + J(θ)_test = -1/m_test * sum(y_test*log(h(x)_test) + (1-y_test)*log(h(x)_test));
     + J(θ)_test = 1/m_test * sum(err(h(x)_test, y_test));
       + err(h(x)_test, y_test) = 1 if h(x)≥0.5, y=0 or if h(x)<0.5, y=1;
       + err(h(x)_test, y_test) = 0 otherwise;
## 模型选择（model selection problem）和训练/验证/测试集（training、validation、test）
 + 模型选择是指同一问题可能有多种模型能够比较理想地实现较低的训练误差，需要通过测试集来选择最佳的模型。
 + 测试集所选择的模型可能会乐观地估计该模型的泛化误差（对训练集和测试集都比较理想，缺少一类该模型未经历的数据集），因此需要引入验证集。
 + 将数据集分成训练集、交叉验证集(cross validation set)、测试集（6：2：2）；
  + 通过训练集找到多种模型，通过交叉验证集选择模型，通过测试集测试泛化误差；
## 诊断偏差（bias）与方差(variance)（欠拟合和过拟合）
 + 高偏差问题：交叉验证误差和训练误差都比较高 (J_cross ≈ J_train) => 欠拟合问题
 + 高方差问题：交叉验证误差较高，训练误差较低 (J_cross >> J_train) => 过拟合问题
## 正则化和偏差/方差
 + 大的正则化参数lambda => 欠拟合，高偏差；
 + 小的正则化参数lambda => 过拟合，高方差；
 + 如何选择正则化参数lambda：
   + 定义几种代价函数：
    + 模型代价函数为：J(θ) = 1/2m * sum( (h(θ)-y)^2) + lambda/2m * sum(θ^2)
    + train代价函数为：J(θ)_train = 1/2m * sum( (h(θ) - y)^2) 
    + cross代价函数为：J(θ)_cross = 1/2m_cross * sum( (h(θ)_cross - y_cross)^2) 
    + test代价函数为：J(θ)_test = 1/2m_test * sum( (h(θ)_test - y_test)^2) 
   + 尝试不同的lambda，分别计算最小化代价函数的Θ参数，然后利用该参数计算J_cross，J_cross最小的一组参数为最佳的lambda。
    + try lambda = 0 -> Θ1 (min(J(θ))) -> J_cross_Θ1
    + try lambda = 0.01 -> Θ2 (min(J(θ))) -> J_cross_Θ2
    + try lambda = 0.02 -> Θ3 (min(J(θ))) -> J_cross_Θ3
    + ...
    + try lambda = 10 -> Θ12 (min(J(θ))) -> J_cross_Θ12
   + 采用测试集（test）来评估上述选择的lambda下的泛化误差。
## 学习曲线
 + 
 
