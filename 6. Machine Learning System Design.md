# 确定执行的优先级
  + 垃圾邮件分类器：
      + 监督学习：
          + x=邮件的features，y=spam (1)或者non-spam (0)
          + features的选取：可以选择100个单词来标识是否是垃圾邮件
              + deal, buy, discount, now, ...（共100个）
              + 如果邮件中包含第j个单词，则xj = 1，否则，xj=0
              + 实际上，通常选择训练集中经常出现的n个单词作为features（n为10000~50000）
          + 如何使垃圾邮件分类器的误差更低
              + 收集更多的数据
              + 复杂的features，基于发件人信息，邮件header
              + 复杂的features，基于邮件信息本身：
                  + discount和discounts是否应该认为一致？
                  + deal和Dealer是否一致？
                  + 感叹号的过度使用等？
              + 检测错误的拼写
# 误差分析
  + 推荐的方式：
      + 快速实施一个简单粗暴的算法，用交叉验证集数据来测试其效果；
      + 绘制学习曲线，判断是否需要更多数据，更多features等；
      + 误差分析：
          + 检查模型错误分类的例子，看他们是否有共同的特征和规律；
# 不对称性分类的误差评估（Error metrics for skewed classes）
  + 癌症分类例子：
      + 逻辑回归模型：测试集误差为1%
          + 假定测试集仅有0.5%的人患有癌症
          + 假定有一个伪模型，该模型不管输入是什么，都输出无癌症，则该伪模型对上述测试集的误差仅0.5% => 偏斜类问题（skewed classes）
          + 仅仅通过误差率的提升来判断算法的改动是否是有益的，并不合适
      + 查准率和召回率（Precision/Recall）
          + 查准率定义为：预测的真值和真实的真值一致的数量 / 预测为真值的数量
              + 预测的真值和真实的真值一致 表示真实的分类为1，预测的分类也为1
              + 预测为真值： 表示不管真实的分类为何，预测的分类均为1
          + 召回率定义为：预测的真值和真实的真值一致的数量 / 真实的分类为真值的数量
              + 预测的真值和真实的真值一致 表示真实的分类为1，预测的分类也为1
              + 真实的分类为真值：不管预测为何，真实的分类为1
          + ![image=]
# 
